{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import tarfile\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_tar_contents(tar_path, extract_path):\n",
    "    \"\"\"Extracts tar file contents into a specified directory.\"\"\"\n",
    "    with tarfile.open(tar_path, 'r') as tar:\n",
    "        tar.extractall(path=extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path= 'E:/Matrice.ai/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_annotations(base_path):\n",
    "    \"\"\"Load annotations from JSON files and combine them.\"\"\"\n",
    "    combined_annotations = []\n",
    "    for phase in ['train', 'val']:  # Test set assumed to have no annotations\n",
    "        with open(os.path.join(base_path, 'annotations', f'instances_{phase}2024.json'), 'r') as file:\n",
    "            data = json.load(file)\n",
    "            for ann in data['annotations']:\n",
    "                img_info = next((img for img in data['images'] if img['id'] == ann['image_id']), None)\n",
    "                if img_info:\n",
    "                    combined_annotations.append({\n",
    "                        'filename': img_info['file_name'],\n",
    "                        'filepath': os.path.join(base_path, 'images', phase, img_info['file_name']),\n",
    "                        'width': img_info['width'],\n",
    "                        'height': img_info['height'],\n",
    "                        'bbox': ann['bbox'],\n",
    "                        'category_id': ann['category_id']\n",
    "                    })\n",
    "    return combined_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_class_frequency(annotations, min_images=50):\n",
    "    \"\"\"Filter annotations to only include classes with at least `min_images` across the dataset.\"\"\"\n",
    "    class_counts = defaultdict(int)\n",
    "    for ann in annotations:\n",
    "        class_counts[ann['category_id']] += 1\n",
    "\n",
    "    # Filter annotations based on class count\n",
    "    filtered_annotations = [ann for ann in annotations if class_counts[ann['category_id']] >= min_images]\n",
    "    return filtered_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(annotations, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):\n",
    "    \"\"\"Split data into train, val, and test sets.\"\"\"\n",
    "    random.shuffle(annotations)\n",
    "    total = len(annotations)\n",
    "    train_end = int(train_ratio * total)\n",
    "    val_end = train_end + int(val_ratio * total)\n",
    "\n",
    "    train_set = annotations[:train_end]\n",
    "    val_set = annotations[train_end:val_end]\n",
    "    test_set = annotations[val_end:]\n",
    "    return train_set, val_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_yolo_annotations(data, output_dir):\n",
    "    \"\"\"Convert annotations to YOLO format and write to files.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for item in data:\n",
    "        label_path = os.path.join(output_dir, os.path.splitext(item['filename'])[0] + '.txt')\n",
    "        with open(label_path, 'w') as file:\n",
    "            x_center = (item['bbox'][0] + item['bbox'][2] / 2) / item['width']\n",
    "            y_center = (item['bbox'][1] + item['bbox'][3] / 2) / item['height']\n",
    "            width = item['bbox'][2] / item['width']\n",
    "            height = item['bbox'][3] / item['height']\n",
    "            file.write(f\"{item['category_id']} {x_center} {y_center} {width} {height}\\n\")\n",
    "        shutil.copy(item['filepath'], output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(tar_path, output_base, sample_size=500):\n",
    "    extract_path = 'temp_dataset'\n",
    "    extract_tar_contents(tar_path, extract_path)\n",
    "\n",
    "    annotations = load_annotations(extract_path)\n",
    "    filtered_annotations = filter_by_class_frequency(annotations)\n",
    "    random_sample = random.sample(filtered_annotations, min(sample_size, len(filtered_annotations)))\n",
    "    train_data, val_data, test_data = split_data(random_sample)\n",
    "\n",
    "    for phase, data in zip(['train', 'val', 'test'], [train_data, val_data, test_data]):\n",
    "        output_dir = os.path.join(output_base, phase)\n",
    "        write_yolo_annotations(data, output_dir)\n",
    "\n",
    "    shutil.rmtree(extract_path)  \n",
    "    \n",
    "tar_path = 'E:/Matrice.ai/deep_fashion.tar'\n",
    "output_base = 'E:/Matrice.ai/output'\n",
    "main(tar_path, output_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
